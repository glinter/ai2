{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FKM-F-XG-t93","executionInfo":{"status":"ok","timestamp":1634031409425,"user_tz":-540,"elapsed":39114,"user":{"displayName":"parrot parrot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16032609930329820738"}},"outputId":"1cd427b5-b2b6-43e9-a810-031ceea4b0ec"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","basic_path = '/content/drive/MyDrive/test/'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"OEqDNedyMeXu"},"source":["# 라이브러리 import\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvEjH9ImMeav"},"source":["def get_device():\n","    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"itiUbxJgMeeM"},"source":["def get_mean_std(channel, training_dataset):\n","  if channel.lower() is 'rgb':\n","    mean_rgb = [np.mean(x.numpy(), axis=(1, 2)) for x,_ in training_dataset]\n","    std_rgb = [np.std(x.numpy(), axis=(1, 2)) for x,_ in training_dataset]\n","\n","    mean_r = np.mean([m[0] for m in mean_rgb])\n","    mean_g = np.mean([m[1] for m in mean_rgb])\n","    mean_b = np.mean([m[2] for m in mean_rgb])\n","\n","    std_r = np.mean([s[0] for s in std_rgb])\n","    std_g = np.mean([s[1] for s in std_rgb])\n","    std_b = np.mean([s[2] for s in std_rgb])\n","    return [mean_r, mean_g, mean_b], [std_r, std_g, std_b]\n","  else:\n","    mean = [np.mean(x.numpy(), axis=(1, 2)) for x,_ in training_dataset]\n","    std = [np.std(x.numpy(), axis=(1, 2)) for x,_ in training_dataset]\n","\n","    return np.mean([m[0] for m in mean]), np.mean([s[0] for s in std])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jEULsgHOg_3a"},"source":["### ResNet 구현"]},{"cell_type":"code","metadata":{"id":"Cx1KitNt4nzD"},"source":["class BottleNeckBlock(nn.Module):\n","  def __init__(self, input_channel_size, output_channel_size, stride):\n","    super(BottleNeckBlock, self).__init__()\n","    self.residual_func = nn.Sequential(\n","            nn.Conv2d(in_channels=input_channel_size, out_channels=output_channel_size, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(output_channel_size),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(in_channels=output_channel_size, out_channels=output_channel_size, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(output_channel_size),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(in_channels=output_channel_size, out_channels=(output_channel_size * 4), kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(output_channel_size * 4),\n","        )\n","    self.myReLU = nn.ReLU()\n","    self.shortcut = nn.Sequential()\n","    if (stride != 1) or (input_channel_size != (output_channel_size * 4)):\n","      self.shortcut = nn.Sequential(\n","            nn.Conv2d(input_channel_size, (output_channel_size * 4), kernel_size=1, stride=stride, bias=False),\n","            nn.BatchNorm2d(output_channel_size * 4)\n","        )\n","  \n","  def forward(self, x):\n","    x = self.residual_func(x) + self.shortcut(x)\n","    x = self.myReLU(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFjlSMHoMehT"},"source":["class MyResNet(nn.Module):\n","  def __init__(self, size_of_channel, number_of_class):\n","    super(MyResNet, self).__init__()\n","    self.base_input_channel = 64\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(size_of_channel, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(inplace=True),\n","        nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","    )\n","    self.conv2 = self.__generate_bottleneck_layer__(64, number_of_layer=3, base_stride=1)\n","    self.conv3 = self.__generate_bottleneck_layer__(128, number_of_layer=4)\n","    self.conv4 = self.__generate_bottleneck_layer__(256, number_of_layer=6)\n","    self.conv5 = self.__generate_bottleneck_layer__(512, number_of_layer=3)\n","\n","    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","    self.fc = nn.Linear(2048, number_of_class)\n","\n","    self.__init_weights__()\n","\n","  def __generate_bottleneck_layer__(self, output_channel_size, number_of_layer, base_stride=2):\n","    strides = [base_stride] + [1] * (number_of_layer - 1)\n","    layers = []\n","    for stride in strides:\n","        layer = BottleNeckBlock(self.base_input_channel, output_channel_size, stride)\n","        self.base_input_channel = output_channel_size * 4\n","        layers.append(layer)\n","    return nn.Sequential(*layers)\n","  \n","  def __init_weights__(self):\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","        if m.bias is not None:\n","          nn.init.constant_(m.bias, 0)\n","      elif isinstance(m, nn.BatchNorm2d):\n","        nn.init.constant_(m.weight, 1)\n","        nn.init.constant_(m.bias, 0)\n","      elif isinstance(m, nn.Linear):\n","        nn.init.normal_(m.weight, 0, 0.01)\n","        nn.init.constant_(m.bias, 0)\n","\n","  def forward(self, x):\n","    output = self.conv1(x)\n","    output = self.conv2(output)\n","    x = self.conv3(output)\n","    x = self.conv4(x)\n","    x = self.conv5(x)\n","    x = self.avg_pool(x)\n","    x = x.view(x.size(0), -1)\n","    x = self.fc(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDgyvjoug8hO"},"source":["### Train / Test 코드"]},{"cell_type":"code","metadata":{"id":"mHtWBQpGeozR"},"source":["def train(device, dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    \n","    for batch, (X, y) in enumerate(dataloader):\n","      X, y = X.to(device), y.to(device)\n","      \n","      pred = model(X.cuda())\n","      loss = loss_fn(pred, y)\n","      \n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      \n","      print('.', end='')\n","      if batch % 100 == 0:\n","          print()\n","          loss, current = loss.item(), batch*len(X)\n","          print(f'loss: {loss:>7f}   [{current:>5d}/{size:>5d}]')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EzE5-jPBeo-p"},"source":["def test(device, dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    \n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            \n","            pred = model(X)\n","            loss = loss_fn(pred, y).item()\n","            test_loss += loss\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UGUdQS81gKoe"},"source":["### Model - CIFAR10"]},{"cell_type":"code","metadata":{"id":"umFI1-dcMekb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634031465720,"user_tz":-540,"elapsed":626,"user":{"displayName":"parrot parrot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16032609930329820738"}},"outputId":"22fae201-c1f7-4f34-f4f1-d6d2ad6b4e2d"},"source":["device = get_device()\n","print('Device:', device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}]},{"cell_type":"code","metadata":{"id":"v02wYGFReMAs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634031502239,"user_tz":-540,"elapsed":34877,"user":{"displayName":"parrot parrot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16032609930329820738"}},"outputId":"0858af5d-f821-4f60-b87d-6d46111f124c"},"source":["training_dataset_cifar10 = datasets.CIFAR10(\n","    root=basic_path + '/data', train=True, download=True, transform=transforms.ToTensor(),\n",")\n","test_dataset_cifar10 = datasets.CIFAR10(\n","    root=basic_path + '/data', train=False, download=True, transform=transforms.ToTensor(),\n",")\n","\n","rgb_mean, rgb_std = get_mean_std('rgb', training_dataset_cifar10)\n","rgb_transform = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.Resize(224),\n","  transforms.Normalize(mean=[rgb_mean], std=[rgb_std])\n","])\n","training_dataset_cifar10.transform = rgb_transform\n","test_dataset_cifar10.transform = rgb_transform"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","metadata":{"id":"pMqgITtteMER","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634031502245,"user_tz":-540,"elapsed":43,"user":{"displayName":"parrot parrot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16032609930329820738"}},"outputId":"50067a2a-046e-47ee-ef90-05a8eb0213b1"},"source":["training_dataloader_cifar10 = DataLoader(training_dataset_cifar10, batch_size=64)\n","test_dataloader_cifar10 = DataLoader(test_dataset_cifar10, batch_size=64)\n","\n","for X, y in test_dataloader_cifar10:\n","  print('Shape of X [N, C, H, W]:', X.shape)\n","  print('Shape of y:', y.shape, y.dtype)\n","  break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X [N, C, H, W]: torch.Size([64, 3, 224, 224])\n","Shape of y: torch.Size([64]) torch.int64\n"]}]},{"cell_type":"code","metadata":{"id":"FBK7SyyIh7rU"},"source":["number_of_cifar10_classes = 10\n","model_cifar10 = MyResNet(3, number_of_cifar10_classes)\n","model_cifar10 = model_cifar10.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k9DS_M_YcKMr"},"source":["# Cuda out of memory\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JkkuQZuOjLMe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634031517986,"user_tz":-540,"elapsed":736,"user":{"displayName":"parrot parrot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16032609930329820738"}},"outputId":"5665b0c3-fdfc-4b03-9311-e306eef62230"},"source":["from torchsummary import summary\n","\n","summary(model_cifar10, input_size=(3, 224, 224))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","  BottleNeckBlock-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","  BottleNeckBlock-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","  BottleNeckBlock-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","  BottleNeckBlock-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","  BottleNeckBlock-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","  BottleNeckBlock-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","  BottleNeckBlock-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","  BottleNeckBlock-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n"," BottleNeckBlock-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n"," BottleNeckBlock-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n"," BottleNeckBlock-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n"," BottleNeckBlock-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n"," BottleNeckBlock-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n","            ReLU-143          [-1, 512, 14, 14]               0\n","          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n","            ReLU-146            [-1, 512, 7, 7]               0\n","          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n","          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n","            ReLU-151           [-1, 2048, 7, 7]               0\n"," BottleNeckBlock-152           [-1, 2048, 7, 7]               0\n","          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n","            ReLU-155            [-1, 512, 7, 7]               0\n","          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n","            ReLU-158            [-1, 512, 7, 7]               0\n","          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n","            ReLU-161           [-1, 2048, 7, 7]               0\n"," BottleNeckBlock-162           [-1, 2048, 7, 7]               0\n","          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n","            ReLU-165            [-1, 512, 7, 7]               0\n","          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n","            ReLU-168            [-1, 512, 7, 7]               0\n","          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n","            ReLU-171           [-1, 2048, 7, 7]               0\n"," BottleNeckBlock-172           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                   [-1, 10]          20,490\n","================================================================\n","Total params: 23,528,522\n","Trainable params: 23,528,522\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 286.55\n","Params size (MB): 89.75\n","Estimated Total Size (MB): 376.88\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","metadata":{"id":"7nyllKB1cQcp"},"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPhX1IlmeMHJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634037461325,"user_tz":-540,"elapsed":5794935,"user":{"displayName":"parrot parrot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16032609930329820738"}},"outputId":"3d8f2e45-1d53-452b-dba3-70393c2ac9f3"},"source":["for epoch in range(5):\n","  print(f'Epoch {epoch + 1}\\n---------------------------------')\n","  train(device, training_dataloader_cifar10, model_cifar10, nn.CrossEntropyLoss(reduction='sum'),\n","        torch.optim.Adam(model_cifar10.parameters(),lr=0.001))\n","  test(device, test_dataloader_cifar10, model_cifar10, nn.CrossEntropyLoss(reduction='sum'))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","---------------------------------\n",".\n","loss: 159.762497   [    0/50000]\n","....................................................................................................\n","loss: 115.318932   [ 6400/50000]\n","....................................................................................................\n","loss: 105.587845   [12800/50000]\n","....................................................................................................\n","loss: 110.483849   [19200/50000]\n","....................................................................................................\n","loss: 104.279259   [25600/50000]\n","....................................................................................................\n","loss: 101.732597   [32000/50000]\n","....................................................................................................\n","loss: 88.263199   [38400/50000]\n","....................................................................................................\n","loss: 92.765923   [44800/50000]\n",".................................................................................Test Error: \n"," Accuracy: 51.4%, Avg loss: 84.732582\n","\n","Epoch 2\n","---------------------------------\n",".\n","loss: 85.598999   [    0/50000]\n","....................................................................................................\n","loss: 86.120781   [ 6400/50000]\n","....................................................................................................\n","loss: 72.164871   [12800/50000]\n","....................................................................................................\n","loss: 76.201874   [19200/50000]\n","....................................................................................................\n","loss: 68.772743   [25600/50000]\n","....................................................................................................\n","loss: 82.209183   [32000/50000]\n","....................................................................................................\n","loss: 64.117165   [38400/50000]\n","....................................................................................................\n","loss: 74.511131   [44800/50000]\n",".................................................................................Test Error: \n"," Accuracy: 63.3%, Avg loss: 65.736419\n","\n","Epoch 3\n","---------------------------------\n",".\n","loss: 55.534008   [    0/50000]\n","....................................................................................................\n","loss: 58.252731   [ 6400/50000]\n","....................................................................................................\n","loss: 48.892960   [12800/50000]\n","....................................................................................................\n","loss: 69.345688   [19200/50000]\n","....................................................................................................\n","loss: 55.892677   [25600/50000]\n","....................................................................................................\n","loss: 65.932793   [32000/50000]\n","....................................................................................................\n","loss: 53.048271   [38400/50000]\n","....................................................................................................\n","loss: 69.962799   [44800/50000]\n",".................................................................................Test Error: \n"," Accuracy: 73.3%, Avg loss: 50.740256\n","\n","Epoch 4\n","---------------------------------\n",".\n","loss: 39.302876   [    0/50000]\n","....................................................................................................\n","loss: 39.947090   [ 6400/50000]\n","....................................................................................................\n","loss: 35.817581   [12800/50000]\n","....................................................................................................\n","loss: 49.658295   [19200/50000]\n","....................................................................................................\n","loss: 37.047569   [25600/50000]\n","....................................................................................................\n","loss: 60.088650   [32000/50000]\n","....................................................................................................\n","loss: 49.671127   [38400/50000]\n","....................................................................................................\n","loss: 53.573795   [44800/50000]\n",".................................................................................Test Error: \n"," Accuracy: 76.1%, Avg loss: 44.914621\n","\n","Epoch 5\n","---------------------------------\n",".\n","loss: 28.508862   [    0/50000]\n","....................................................................................................\n","loss: 31.025297   [ 6400/50000]\n","....................................................................................................\n","loss: 28.178974   [12800/50000]\n","....................................................................................................\n","loss: 34.514801   [19200/50000]\n","....................................................................................................\n","loss: 37.509251   [25600/50000]\n","....................................................................................................\n","loss: 45.886940   [32000/50000]\n","....................................................................................................\n","loss: 41.667843   [38400/50000]\n","....................................................................................................\n","loss: 45.198078   [44800/50000]\n",".................................................................................Test Error: \n"," Accuracy: 76.7%, Avg loss: 44.435188\n","\n"]}]},{"cell_type":"code","metadata":{"id":"WMT7VjK6eMKd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634037472075,"user_tz":-540,"elapsed":1489,"user":{"displayName":"parrot parrot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16032609930329820738"}},"outputId":"d10d8871-5c80-48cc-9cac-059870309659"},"source":["dest_model_path = basic_path + 'resnet_models/model_cifar10_v2.pth'\n","print(dest_model_path)\n","torch.save(model_cifar10.state_dict(), dest_model_path)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/test/resnet_models/model_cifar10_v2.pth\n"]}]}]}